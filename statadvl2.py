#!/usr/bin/env python
# coding: utf-8

# # Q1: What is the difference between a t-test and a z-test? Provide an example scenario where you would use each type of test.

#  A t-test and a z-test are both statistical tests used to make inferences about population parameters based on sample data. However, there are some differences between the two tests, primarily related to the assumptions made about the population and the sample size.
# 
# A z-test assumes that the sample comes from a normally distributed population, and the population standard deviation is known. This test is used when the sample size is large (typically, n > 30) and the population variance is known or can be assumed to be known. For example, if a company wants to test if the mean height of their employees is different from the national average, and they know the standard deviation of the population height, they can use a z-test.
# 
# On the other hand, a t-test assumes that the sample comes from a normally distributed population, and the population standard deviation is unknown. This test is used when the sample size is small (typically, n < 30) or when the population variance is unknown. For example, if a researcher wants to test if a new drug has a different effect than a placebo, they can use a t-test to compare the mean scores of two groups of participants.
# 
# Example scenarios:
# 
# A company wants to compare the mean salary of their employees to the national average salary. They have a large sample size (n>30) and know the population standard deviation. They can use a z-test to make this comparison.
# 
# A researcher wants to compare the mean test scores of two groups of students. They have a small sample size (n<30) and do not know the population standard deviation. They can use a t-test to make this comparison.

# In[ ]:





# # Q2: Differentiate between one-tailed and two-tailed tests.

# In hypothesis testing, the null hypothesis (H0) is a statement about a population parameter that is assumed to be true unless there is sufficient evidence to reject it in favor of an alternative hypothesis (Ha). The alternative hypothesis is the statement that the researcher is trying to support.
# 
# One-tailed tests and two-tailed tests are types of hypothesis tests that differ in the directionality of the alternative hypothesis.
# 
# A one-tailed test is a hypothesis test in which the alternative hypothesis specifies the direction of the effect or difference being tested. That is, the researcher is interested in whether the population parameter is either greater than or less than a certain value, but not both. Therefore, the rejection region for the null hypothesis is only on one side of the distribution. A one-tailed test is often used when the researcher has a specific directional hypothesis or when there is a theoretical or practical reason to expect an effect in a specific direction.
# 
# For example, a one-tailed test might be used to test the hypothesis that a new medication will decrease the amount of time it takes for patients to fall asleep. The alternative hypothesis would be that the medication decreases the amount of time it takes for patients to fall asleep, and the null hypothesis would be that the medication has no effect on the amount of time it takes for patients to fall asleep.
# 
# In contrast, a two-tailed test is a hypothesis test in which the alternative hypothesis does not specify the direction of the effect or difference being tested. That is, the researcher is interested in whether the population parameter is different from a certain value in any direction. Therefore, the rejection region for the null hypothesis is split between both sides of the distribution. A two-tailed test is often used when the researcher has no specific directional hypothesis or when there is no theoretical or practical reason to expect an effect in a specific direction.
# 
# For example, a two-tailed test might be used to test the hypothesis that the mean weight of male and female newborns is the same. The alternative hypothesis would be that the mean weight of male and female newborns is different, and the null hypothesis would be that the mean weight of male and female newborns is equal.
# 
# In summary, one-tailed tests and two-tailed tests differ in the directionality of the alternative hypothesis, and the choice between the two depends on the research question and the directional nature of the hypothesis.

# In[ ]:





# # Q3: Explain the concept of Type 1 and Type 2 errors in hypothesis testing. Provide an example scenario for each type of error.

# In hypothesis testing, Type I and Type II errors are two types of errors that can occur when testing a hypothesis.
# 
# Type I error is the error that occurs when the null hypothesis is rejected when it is actually true. In other words, it is the false positive error, where we reject the null hypothesis even though it is correct. The probability of making a Type I error is denoted by alpha (α) and is often set at 0.05 or 0.01.
# 
# For example, suppose a researcher is testing the effectiveness of a new medication on a disease. The null hypothesis is that the medication has no effect on the disease, and the alternative hypothesis is that the medication has an effect. If the researcher rejects the null hypothesis and concludes that the medication is effective, but in reality, it is not, then a Type I error has occurred.
# 
# Type II error is the error that occurs when the null hypothesis is not rejected when it is actually false. In other words, it is the false negative error, where we fail to reject the null hypothesis even though it is incorrect. The probability of making a Type II error is denoted by beta (β).
# 
# For example, suppose a researcher is testing the effectiveness of a new medication on a disease. The null hypothesis is that the medication has no effect on the disease, and the alternative hypothesis is that the medication has an effect. If the researcher fails to reject the null hypothesis and concludes that the medication is not effective, but in reality, it is effective, then a Type II error has occurred.
# 
# The relationship between Type I and Type II errors is inverse, meaning that decreasing the probability of one type of error increases the probability of the other type of error.
# 
# Example scenario:
# 
# Type I error: A car alarm system is designed to go off if an intruder tries to break in. However, if the alarm goes off when no one is trying to break in, it is a false positive, which is a Type I error.
# 
# Type II error: A pregnancy test is designed to detect the presence of the hormone hCG, which indicates pregnancy. However, if the test does not detect hCG when the woman is actually pregnant, it is a false negative, which is a Type II error.

# In[ ]:





# # Q4: Explain Bayes's theorem with an example.

# Bayes's theorem is a mathematical formula used to calculate the conditional probability of an event based on prior knowledge of related events. It is named after Thomas Bayes, an 18th-century statistician, and philosopher.
# 
# Bayes's theorem can be expressed as follows:
# 
# P(A|B) = P(B|A) * P(A) / P(B)
# 
# where P(A|B) is the probability of event A given event B has occurred, P(B|A) is the probability of event B given that event A has occurred, P(A) is the prior probability of event A, and P(B) is the prior probability of event B.
# 
# An example scenario where Bayes's theorem can be applied is in medical diagnosis. Suppose a patient exhibits certain symptoms that may indicate the presence of a disease. The probability of having the disease given the symptoms can be calculated using Bayes's theorem.
# 
# Let's say that the disease is present in 1% of the population, and the probability of a person exhibiting the symptoms given that they have the disease is 90%. On the other hand, the probability of a person exhibiting the symptoms without having the disease is 10%. Using this information, we can apply Bayes's theorem to calculate the probability of a person having the disease given that they exhibit the symptoms.
# 
# P(Disease|Symptoms) = P(Symptoms|Disease) * P(Disease) / P(Symptoms)
# 
# where P(Disease|Symptoms) is the probability of having the disease given the symptoms, P(Symptoms|Disease) is the probability of exhibiting the symptoms given the disease, P(Disease) is the prior probability of having the disease, and P(Symptoms) is the prior probability of exhibiting the symptoms.
# 
# Plugging in the values, we get:
# 
# P(Disease|Symptoms) = 0.90 * 0.01 / ((0.90 * 0.01) + (0.10 * 0.99))
# 
# = 0.08
# 
# Therefore, the probability of having the disease given the symptoms is 8%. This means that even though the patient exhibits the symptoms, there is still only an 8% chance of having the disease.

# In[ ]:





# # Q5: What is a confidence interval? How to calculate the confidence interval, explain with an example.

# A confidence interval is a range of values that is likely to contain the true value of a population parameter with a certain degree of confidence. In other words, it is a range of values around a sample statistic that is likely to contain the true population parameter value with a certain level of certainty or probability.
# 
# To calculate a confidence interval, we need to know the sample mean, sample size, and standard deviation (or standard error) of the sample statistic. The formula for a confidence interval is:
# 
# Confidence interval = sample mean ± (z-score * standard error)
# 
# where z-score is the number of standard deviations corresponding to the desired level of confidence. For example, for a 95% confidence interval, the z-score would be 1.96.
# 
# Here's an example of how to calculate a confidence interval:
# 
# Suppose we want to estimate the average height of all people in a city. We take a random sample of 50 people and find that the sample mean height is 170 cm, and the sample standard deviation is 5 cm.
# 
# To calculate a 95% confidence interval for the population mean height, we need to first calculate the standard error. The standard error is calculated as:
# 
# Standard error = sample standard deviation / sqrt(sample size)
# 
# = 5 / sqrt(50)
# 
# = 0.71
# 
# Next, we can calculate the confidence interval as:
# 
# Confidence interval = 170 ± (1.96 * 0.71)
# 
# = 168.6 to 171.4 cm
# 
# This means that we can be 95% confident that the true population mean height falls within the range of 168.6 to 171.4 cm. We can interpret this as if we repeat this sampling process many times, 95% of the time, the true population mean height will be contained within this interval.

# In[ ]:





# # Q6. Use Bayes' Theorem to calculate the probability of an event occurring given prior knowledge of the event's probability and new evidence. Provide a sample problem and solution.

# Suppose a new medical test has been developed to detect a certain disease, which affects 1% of the population. The test has a false positive rate of 5%, meaning that 5% of the time, a healthy person will test positive for the disease. The test also has a false negative rate of 10%, meaning that 10% of the time, a person with the disease will test negative. Suppose a person takes the test and receives a positive result. What is the probability that the person actually has the disease?
# 
# Let's define some terms first:
# 
# A: the event that the person has the disease B: the event that the person tests positive for the disease We want to find P(A|B), the probability that the person has the disease given a positive test result. We can use Bayes' theorem to calculate this as follows:
# 
# P(A|B) = P(B|A) * P(A) / P(B)
# 
# where P(B|A) is the probability of testing positive given that the person has the disease, P(A) is the prior probability of the person having the disease, and P(B) is the probability of testing positive for the disease.
# 
# Using the information given in the problem, we can calculate these probabilities as follows:
# 
# P(B|A) = 1 - 0.10 = 0.90 (the probability of testing positive given that the person has the disease is 90%) P(A) = 0.01 (the prior probability of the person having the disease is 1%) P(B) = P(B|A) * P(A) + P(B|not A) * P(not A) = 0.90 * 0.01 + 0.05 * 0.99 (the probability of testing positive is the sum of the probability of a true positive and a false positive) Plugging these values into the Bayes' theorem formula, we get:
# 
# P(A|B) = 0.90 * 0.01 / (0.90 * 0.01 + 0.05 * 0.99)
# 
# = 0.15
# 
# Therefore, the probability that the person actually has the disease given a positive test result is 15%. This means that the test is not very accurate, and there is still a high chance of a false positive result.

# In[ ]:





# # Q7. Calculate the 95% confidence interval for a sample of data with a mean of 50 and a standard deviation of 5. Interpret the results.

# To calculate the 95% confidence interval for a sample of data with a mean of 50 and a standard deviation of 5, we need to use the formula:
# 
# Confidence interval = sample mean ± (z-score * standard error)
# 
# where the z-score for a 95% confidence level is 1.96, and the standard error is calculated as:
# 
# Standard error = standard deviation / sqrt(sample size)
# 
# Assuming a large enough sample size (n > 30), we can use the sample standard deviation as an estimate of the population standard deviation, and the sample size as the sample size. Therefore, we can calculate the standard error as:
# 
# Standard error = 5 / sqrt(n)
# 
# Since the sample size is not given in the problem, we cannot calculate the confidence interval. However, assuming a sample size of 30 or more, the standard error would be:
# 
# Standard error = 5 / sqrt(30) = 0.91
# 
# Using the formula for the confidence interval, we can calculate:
# 
# Confidence interval = 50 ± (1.96 * 0.91)
# 
# = 47.23 to 52.77
# 
# This means that we can be 95% confident that the true population mean falls within the range of 47.23 to 52.77. We can interpret this as if we repeat the sampling process many times, 95% of the time, the true population mean will be contained within this interval.
# 
# In other words, we are 95% confident that the true population mean is between 47.23 and 52.77 based on this sample data.

# In[ ]:





# # Q8. What is the margin of error in a confidence interval? How does sample size affect the margin of error?Provide an example of a scenario where a larger sample size would result in a smaller margin of error.

# The margin of error in a confidence interval is the range of values around the sample estimate that we are confident contains the true population value. It represents the amount of uncertainty in our estimate due to sampling error.
# 
# The margin of error is affected by several factors, including the level of confidence desired, the sample size, and the variability of the data. In general, a larger sample size results in a smaller margin of error, all else being equal. This is because a larger sample size reduces the effect of random sampling error, and thus increases the precision of the estimate.
# 
# For example, suppose we want to estimate the proportion of adults in a city who support a particular political candidate, and we take a random sample of 100 adults. The sample proportion is 0.6, which means that 60% of the sample supports the candidate. We want to construct a 95% confidence interval for the true population proportion.
# 
# Assuming a normal distribution and using the formula for the margin of error, we can calculate:
# 
# Margin of error = z * sqrt(p_hat * (1 - p_hat) / n)
# 
# where z is the critical value for a 95% confidence interval, p_hat is the sample proportion, and n is the sample size.
# 
# Using a standard normal table, we find that the critical value for a 95% confidence interval is 1.96. Plugging in the values, we get:
# 
# Margin of error = 1.96 * sqrt(0.6 * 0.4 / 100)
# 
# = 0.098
# 
# This means that we are 95% confident that the true population proportion of adults who support the candidate is between 0.502 and 0.698 (0.6 ± 0.098).
# 
# Now, suppose we increase the sample size to 400. Using the same formula, we can calculate the new margin of error as:
# 
# Margin of error = 1.96 * sqrt(0.6 * 0.4 / 400)
# 
# = 0.049
# 
# This means that we are 95% confident that the true population proportion of adults who support the candidate is between 0.551 and 0.649 (0.6 ± 0.049).
# 
# As we can see, the larger sample size results in a smaller margin of error, which means that our estimate is more precise and we can be more confident in our conclusion.

# In[ ]:





# # Q9. Calculate the z-score for a data point with a value of 75, a population mean of 70, and a population standard deviation of 5. Interpret the results.

# # To calculate the z-score for a data point with a value of 75, a population mean of 70, and a population standard deviation of 5, we use the formula:
# 
# z = (x - μ) / σ
# 
# where x is the value of the data point, μ is the population mean, and σ is the population standard deviation.
# 
# Plugging in the values, we get:
# 
# z = (75 - 70) / 5
# 
# z = 1
# 
# This means that the data point of 75 is 1 standard deviation above the population mean. The z-score tells us how many standard deviations a data point is from the population mean. In this case, the z-score of 1 indicates that the data point is one standard deviation above the mean.
# 
# The interpretation of the z-score is important when considering the normal distribution. In a normal distribution, a z-score of 0 means the data point is at the mean, a z-score of 1 means the data point is one standard deviation above the mean, and a z-score of -1 means the data point is one standard deviation below the mean.

# In[ ]:





# # Q10. In a study of the effectiveness of a new weight loss drug, a sample of 50 participants lost an average of 6 pounds with a standard deviation of 2.5 pounds. Conduct a hypothesis test to determine if the drug is significantly effective at a 95% confidence level using a t-test.

# To conduct a hypothesis test to determine if the weight loss drug is significantly effective at a 95% confidence level using a t-test, we need to state our null and alternative hypotheses:
# 
# Null hypothesis: The average weight loss for participants taking the new drug is not significantly different from 0. Alternative hypothesis: The average weight loss for participants taking the new drug is significantly greater than 0. We will use a one-sample t-test, since we are comparing the mean weight loss of the sample to a hypothesized population mean of 0.
# 
# We can calculate the t-statistic using the formula:
# 
# t = (x̄ - μ) / (s / √n)
# 
# where x̄ is the sample mean, μ is the hypothesized population mean (0 in this case), s is the sample standard deviation, and n is the sample size.
# 
# Plugging in the values, we get:
# 
# t = (6 - 0) / (2.5 / √50)
# 
# t = 15.39
# 
# Using a t-table with 49 degrees of freedom and a significance level of 0.05 (since we want a 95% confidence level), we find the critical t-value to be 1.677. Since our calculated t-value of 15.39 is greater than the critical t-value of 1.677, we can reject the null hypothesis and conclude that the average weight loss for participants taking the new drug is significantly greater than 0 at a 95% confidence level.
# 
# Therefore, we can conclude that there is evidence to support the effectiveness of the new weight loss drug.

# In[ ]:





# # Q11. In a survey of 500 people, 65% reported being satisfied with their current job. Calculate the 95% confidence interval for the true proportion of people who are satisfied with their job.

# To calculate the 95% confidence interval for the true proportion of people who are satisfied with their job, we can use the following formula:
# 
# CI = p̂ ± z*(√(p̂(1-p̂)/n))
# 
# where CI is the confidence interval, p̂ is the sample proportion, z* is the critical z-value for the desired confidence level (1.96 for 95% confidence level), and n is the sample size.
# 
# Plugging in the values, we get:
# 
# CI = 0.65 ± 1.96*(√((0.65)(1-0.65)/500))
# 
# CI = 0.65 ± 0.0465
# 
# The 95% confidence interval for the true proportion of people who are satisfied with their job is (0.6035, 0.6965).
# 
# Interpretation: We can be 95% confident that the true proportion of people who are satisfied with their job falls between 0.6035 and 0.6965. This means that if we were to repeat this survey many times, 95% of the time the proportion of people satisfied with their job would fall within this interval.

# In[ ]:





# # Q12. A researcher is testing the effectiveness of two different teaching methods on student performance.Sample A has a mean score of 85 with a standard deviation of 6, while sample B has a mean score of 82 with a standard deviation of 5. Conduct a hypothesis test to determine if the two teaching methods have a significant difference in student performance using a t-test with a significance level of 0.01.

# # To conduct a hypothesis test to determine if there is a significant difference in student performance between the two teaching methods using a t-test, we need to state our null and alternative hypotheses:
# 
# Null hypothesis: There is no significant difference in student performance between the two teaching methods (μA - μB = 0). Alternative hypothesis: There is a significant difference in student performance between the two teaching methods (μA - μB ≠ 0). We will use a two-sample t-test assuming unequal variances, since the sample standard deviations are different.
# 
# We can calculate the t-statistic using the formula:
# 
# t = (x̄A - x̄B - D) / √(sA²/nA + sB²/nB)
# 
# where x̄A and x̄B are the sample means, sA and sB are the sample standard deviations, nA and nB are the sample sizes, and D is the hypothesized difference in population means (0 in this case).
# 
# Plugging in the values, we get:
# 
# t = (85 - 82 - 0) / √((6²/30) + (5²/30))
# 
# t = 2.02
# 
# Using a t-table with degrees of freedom (df) equal to the smaller of nA-1 and nB-1 (28 in this case) and a significance level of 0.01, we find the critical t-value to be ±2.763. Since our calculated t-value of 2.02 falls within the range between -2.763 and 2.763, we fail to reject the null hypothesis and conclude that there is no significant difference in student performance between the two teaching methods at a significance level of 0.01.
# 
# Therefore, we can conclude that there is not enough evidence to suggest that the two teaching methods have significantly different effects on student performance.

# In[ ]:





# # Q13. A population has a mean of 60 and a standard deviation of 8. A sample of 50 observations has a mean of 65. Calculate the 90% confidence interval for the true population mea

# To calculate the 90% confidence interval for the true population mean, we will use the formula:
# 
# CI = x̄ ± z*(σ/√n)
# 
# where x̄ is the sample mean, σ is the population standard deviation, n is the sample size, and z is the critical value from the standard normal distribution for the desired level of confidence.
# 
# Since the sample size is large (n=50), we can use the z-distribution instead of the t-distribution. For a 90% confidence level, the critical value is 1.645.
# 
# Plugging in the values, we get:
# 
# CI = 65 ± 1.645*(8/√50)
# 
# CI = 65 ± 2.34
# 
# The 90% confidence interval for the true population mean is (62.66, 67.34).
# 
# Interpretation: We are 90% confident that the true population mean lies within the interval (62.66, 67.34) based on the sample mean of 65 and a sample size of 50.

# In[ ]:





# # Q14. In a study of the effects of caffeine on reaction time, a sample of 30 participants had an average reaction time of 0.25 seconds with a standard deviation of 0.05 seconds. Conduct a hypothesis test to determine if the caffeine has a significant effect on reaction time at a 90% confidence level using a t-test.
# To conduct a hypothesis test to determine if caffeine has a significant effect on reaction time, we need to follow the following steps:
# 
# Step 1: State the null and alternative hypotheses. The null hypothesis is that there is no significant difference in reaction time between participants who consumed caffeine and those who did not consume caffeine. The alternative hypothesis is that there is a significant difference in reaction time between participants who consumed caffeine and those who did not consume caffeine.
# 
# H0: μ1 = μ2 (there is no significant difference in reaction time between caffeine and non-caffeine groups) Ha: μ1 ≠ μ2 (there is a significant difference in reaction time between caffeine and non-caffeine groups)
# 
# where μ1 is the population mean reaction time for the caffeine group and μ2 is the population mean reaction time for the non-caffeine group.
# 
# Step 2: Determine the level of significance and select the appropriate test statistic. The level of significance is 0.10 or 90% confidence level. Since the sample size is small (n < 30), we will use a t-test.
# 
# Step 3: Calculate the test statistic. We can calculate the t-statistic using the formula:
# 
# t = (x̄1 - x̄2) / (s/√n)
# 
# where x̄1 is the sample mean reaction time for the caffeine group, x̄2 is the sample mean reaction time for the non-caffeine group, s is the pooled standard deviation, and n is the sample size for each group.
# 
# To calculate the pooled standard deviation, we use the formula:
# 
# s = √[(s1^2 + s2^2) / 2]
# 
# where s1 and s2 are the sample standard deviations for the caffeine and non-caffeine groups, respectively.
# 
# Plugging in the values, we get:
# 
# t = (0.25 - μ2) / (0.05/√30)
# 
# where μ2 is the unknown population mean reaction time for the non-caffeine group.
# 
# To find the critical t-value for a 90% confidence level with 28 degrees of freedom (30 - 2), we can use a t-table or calculator, which gives us a critical t-value of ±1.699.
# 
# Step 4: Determine the p-value and make a decision. Using a t-table or calculator, we find the p-value to be less than 0.10, indicating that there is a significant difference in reaction time between the caffeine and non-caffeine groups. Therefore, we reject the null hypothesis and conclude that caffeine has a significant effect on reaction time at a 90% confidence level.
# 
# Note: If the p-value is greater than 0.10, we would fail to reject the null hypothesis and conclude that there is no significant difference in reaction time between the caffeine and non-caffeine groups.
# 
#  

# In[ ]:




